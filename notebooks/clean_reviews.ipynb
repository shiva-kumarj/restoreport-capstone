{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blahb\\AppData\\Local\\Temp\\ipykernel_19500\\2788157288.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Users\\blahb\\anaconda3\\envs\\capstone_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-25 17:38:58 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json: 370kB [00:00, 5.99MB/s]                    \n",
      "2024-01-25 17:38:58 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-01-25 17:38:59 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2024-01-25 17:38:59 WARNING: GPU requested, but is not available!\n",
      "2024-01-25 17:38:59 INFO: Using device: cpu\n",
      "2024-01-25 17:38:59 INFO: Loading: tokenize\n",
      "2024-01-25 17:38:59 INFO: Loading: mwt\n",
      "2024-01-25 17:38:59 INFO: Loading: sentiment\n",
      "2024-01-25 17:39:00 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import stanza\n",
    "import os\n",
    "import logging\n",
    "\n",
    "log_file_path = os.path.abspath('..\\logs\\lemmatization.log')\n",
    "\n",
    "logging.basicConfig(filename='..\\logs\\lemmatization.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "nlp = stanza.Pipeline(processors='tokenize,sentiment', lang='en', use_gpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.read_csv('../data/processed/business.csv')\n",
    "df_iter = pd.read_json('../data/raw/yelp_academic_dataset_review.json', lines=True, chunksize=100, encoding='utf-8')\n",
    "df = next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_b_ids = list(business_df['business_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retaining only relevant attributes\n",
    "df = df[['business_id', 'stars', 'useful', 'text', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews of restaurants\n",
    "filtered_df = df[df['business_id'].isin(restaurant_b_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_datetime(chunk):\n",
    "  assert not chunk['date'].isnull().any(), \"AssertionError: Null values found in the \\\"date\\\" column\"\n",
    "  assert chunk['date'].dtype == 'datetime64[ns]', \"AssertionError: dtype mismatch of date column\"\n",
    "  assert not ((chunk['date'].dt.month > 12) | (chunk['date'].dt.month < 1)).any(), \"AssertionError: Month should be between 1 and 12 (inclusive)\"\n",
    "  assert not ((chunk['date'].dt.day > 31) | (chunk['date'].dt.day < 1)).any(), \"AssertionError: Date should be between 1 and 31 (inclusive)\"\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_numerical_col(chunk):\n",
    "  numerical_col = ['stars', 'useful']\n",
    "  for col in numerical_col:\n",
    "    assert chunk[col].dtype == 'int64', f\"AssertionError: {col} should have data type 'int64'\" \n",
    "    assert not chunk[col].isnull().any(), f\"AssertionError: {col} should not have missing values\"\n",
    "  \n",
    "  assert (1.0 <= chunk['stars'].min() <= 5.0), \"AssertionError: 'stars' should be in the range of 1 to 5\"\n",
    "  assert (1.0 <= chunk['stars'].max() <= 5.0), \"AssertionError: 'stars' should be in the range of 1 to 5\"\n",
    "\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(chunk):\n",
    "  assert not chunk['business_id'].isnull().any(), \"AssertionError: 'Business id' should not have missing values\"\n",
    "  validate_numerical_col(chunk)\n",
    "  validate_datetime(chunk)\n",
    "  assert not chunk.isnull().any().any(), \"AssertionError: Chunk must not contain any missing values\"\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(inp_text):\n",
    "  # lower case\n",
    "  inp_text = inp_text.lower()\n",
    "  # extract out all alphabet, numbers, and select special characters and join them back together with a 'space'.\n",
    "  regex_pattern = r'[a-zA-Z0-9s!?.\" \"]+'\n",
    "  matched_substrings = re.findall(regex_pattern, inp_text)\n",
    "  cleaned_text = ''.join(matched_substrings)\n",
    "  # replace all non alphabetic, space and period characters with a period\n",
    "  cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.]', '.', cleaned_text)\n",
    "  \n",
    "  return cleaned_text\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stars(stars_column):\n",
    "  # choice_of_ratings = [np.floor(stars_column.mean()), stars_column.mode(), stars_column.quantile(0.5)]\n",
    "  choice_of_ratings = [3, 4, 5]\n",
    "  stars_column = stars_column.fillna(np.random.choice(choice_of_ratings))\n",
    "  stars_column = stars_column.astype('int')\n",
    "  return stars_column\n",
    "\n",
    "def clean_useful(useful_column):\n",
    "  useful_column = useful_column.fillna(useful_column.mode())\n",
    "  useful_column = useful_column.astype('int')\n",
    "  return useful_column\n",
    "\n",
    "def clean_date(date_column):\n",
    "  date_column = pd.to_datetime(date_column)\n",
    "  return date_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(chunk):\n",
    "  chunk.loc[:, 'business_id'] = chunk['business_id'].dropna()\n",
    "  chunk.loc[:, 'stars'] = clean_stars(chunk['stars'])\n",
    "  chunk.loc[:, 'useful'] = clean_useful(chunk['useful'])\n",
    "  chunk.loc[:, 'date'] = clean_date(chunk['date'])\n",
    "  chunk.loc[:, 'text'] = chunk['text'].apply(lambda x: clean_text(x))\n",
    "  return chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ~~Spell correction (did not add any value, very time taking)~~\n",
    "2. ~~(Sentence, Sentiment) map using Stanza.~~\n",
    "3. ~~Flatten (sentence, sentiment) map into individual rows.~~\n",
    "4. annotate sentence into one word \"business area\" using OpenAI or other libraries available on github. \n",
    "   1. Note: OpenAI is paid but gave the best results so far. better than manual labelling, semi-supervised labelling, and stanza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = clean_data(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_data(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the sentiment of each noun from a sentence\n",
    "def get_line_sentiment(review, record_count):\n",
    "  sentiment_map = {}\n",
    "  for sentence in nlp(review).sentences:\n",
    "    sentiment = sentence.sentiment\n",
    "    sentiment_map[sentence.text] = sentiment\n",
    "  record_count[0] += 1\n",
    "  logging.info(f'get_line_sentiment: {record_count[0]}/{record_count[1]}.')\n",
    "  return sentiment_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(cleaned_data)\n",
    "record_count = [0, batch_size]\n",
    "cleaned_data = cleaned_data.assign(sentiment_dict=cleaned_data['text'].apply(lambda x: get_line_sentiment(x, record_count)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_noun(sentiment_dict):\n",
    "  \n",
    "  return sentiment_dict.keys()\n",
    "\n",
    "def get_sentiment_value(sentiment_dict):\n",
    "  \n",
    "  return sentiment_dict.values()\n",
    "\n",
    "def clean_dataframe(df):\n",
    "  # fix date type\n",
    "  # df.loc[:, 'date'] = pd.to_datetime(df['date'])\n",
    "  # df = df.drop(['text', 'corrected_text'], axis=1)\n",
    "  df.loc[:, 'statement'] = df['sentiment_dict'].apply(get_sentiment_noun)\n",
    "  df.loc[:, 'sentiment'] = df['sentiment_dict'].apply(get_sentiment_value)\n",
    "\n",
    "  df = df.explode(['statement', 'sentiment'])\n",
    "\n",
    "  df = df.drop('sentiment_dict', axis=1)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_data = cleaned_data.copy()\n",
    "cleaned_data = clean_dataframe(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>statement</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>if you decide to eat here just be aware it is ...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>if you decide to eat here just be aware it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>if you decide to eat here just be aware it is ...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>we have tried it multiple times because i want...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>if you decide to eat here just be aware it is ...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>i have been to its other locations in nj and n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>if you decide to eat here just be aware it is ...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>the food is good but it takes a very long time...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>if you decide to eat here just be aware it is ...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>the waitstaff is very young but usually pleasant.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  stars  useful  \\\n",
       "0  XQfwVwDr-v0ZS3_CbbE5Xw      3       0   \n",
       "0  XQfwVwDr-v0ZS3_CbbE5Xw      3       0   \n",
       "0  XQfwVwDr-v0ZS3_CbbE5Xw      3       0   \n",
       "0  XQfwVwDr-v0ZS3_CbbE5Xw      3       0   \n",
       "0  XQfwVwDr-v0ZS3_CbbE5Xw      3       0   \n",
       "\n",
       "                                                text                date  \\\n",
       "0  if you decide to eat here just be aware it is ... 2018-07-07 22:09:11   \n",
       "0  if you decide to eat here just be aware it is ... 2018-07-07 22:09:11   \n",
       "0  if you decide to eat here just be aware it is ... 2018-07-07 22:09:11   \n",
       "0  if you decide to eat here just be aware it is ... 2018-07-07 22:09:11   \n",
       "0  if you decide to eat here just be aware it is ... 2018-07-07 22:09:11   \n",
       "\n",
       "                                           statement sentiment  \n",
       "0  if you decide to eat here just be aware it is ...         1  \n",
       "0  we have tried it multiple times because i want...         1  \n",
       "0  i have been to its other locations in nj and n...         2  \n",
       "0  the food is good but it takes a very long time...         1  \n",
       "0  the waitstaff is very young but usually pleasant.         2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "capstone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
